{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of files and end times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of Rm files we process as (R,t0,t1,2) tuple\n",
    "Rms=[\n",
    "    ('R5e2',50,4000,-1,4.97013),\n",
    "    #('R1000',50,1200,-1,9.940268924035474),\n",
    "    #('R2000',50,1000,-1),\n",
    "    #('R3000',50,1000,-1),\n",
    "    #('R4000',50,1000,-1),\n",
    "    ('R5e3',50,1000,-1,49.70134462017736),\n",
    "    #('R6000',50,1000,-1),\n",
    "    #('R7000',50,1000,-1),\n",
    "    #('R8000',50,1000,-1),\n",
    "    #('R9000',50,1000,-1),\n",
    "    #('R10000',50,1200,-1),\n",
    "    ('R15e3',50,1500,-1,149.09657903158052),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary data handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mf(fname='mfields.npz'):\n",
    "    mf = np.load(fname)\n",
    "    return mf['bxm'], mf['bym'], mf['jxm'], mf['jym'], mf['emfx'], mf['emfy']\n",
    "\n",
    "def ave_t(arr,tone=1000,ttwo=2000):\n",
    "    print(f't1: {tone}, t2: {ttwo}')\n",
    "    return np.mean(arr[tone:ttwo,:],axis=0)\n",
    "\n",
    "def ave_z(arr,zone=128,ztwo=-1):\n",
    "    print(f'z1: {zone}, z2: {ztwo}')\n",
    "    return np.mean(arr[:,zone:ztwo],axis=1)\n",
    "\n",
    "def gen_df_tave(fname='mfields.npz',t1=1000,t2=2000,verbose=1,name_conv=1):\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Generating time averaged dataframe with t1: {t1} and t2: {t2}\")\n",
    "  \n",
    "    if name_conv:\n",
    "        bxm,bym,jxm,jym,Exm,Eym = read_mf(fname=fname)\n",
    "    else:\n",
    "        bxm,bym,jxm,jym,Exm,Eym = read_mf2(fname=fname)\n",
    "\n",
    "    return pd.DataFrame.from_dict({\n",
    "        'Bx': ave_t(bxm,tone=t1,ttwo=t2),\n",
    "        'By': ave_t(bym,tone=t1,ttwo=t2),\n",
    "        'Jx': ave_t(jxm,tone=t1,ttwo=t2),\n",
    "        'Jy': ave_t(jym,tone=t1,ttwo=t2),\n",
    "        'Ex': -ave_t(Exm,tone=t1,ttwo=t2),\n",
    "        'Ey': -ave_t(Eym,tone=t1,ttwo=t2)        \n",
    "        })\n",
    "\n",
    "def gen_df_zave(fname='mfields.npz',z1=128,z2=-1,verbose=1,name_conv=1):\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Generating z averaged dataframe with z1: {z1} and z2: {z2}\")\n",
    "  \n",
    "    if name_conv:\n",
    "        bxm,bym,jxm,jym,Exm,Eym = read_mf(fname=fname)\n",
    "    else:\n",
    "        bxm,bym,jxm,jym,Exm,Eym = read_mf2(fname=fname)\n",
    "\n",
    "    return pd.DataFrame.from_dict({\n",
    "        'Bx': ave_z(bxm,zone=z1,ztwo=z2),\n",
    "        'By': ave_z(bym,zone=z1,ztwo=z2),\n",
    "        'Jx': ave_z(jxm,zone=z1,ztwo=z2),\n",
    "        'Jy': ave_z(jym,zone=z1,ztwo=z2),\n",
    "        'Ex': -ave_z(Exm,zone=z1,ztwo=z2),\n",
    "        'Ey': -ave_z(Eym,zone=z1,ztwo=z2)        \n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize the files we process. This also allows us to check our limits for `t1` and `t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(Rms), figsize=(6,12), sharex=False)\n",
    "plt.subplots_adjust(left=0.2, hspace=0.25)\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    Rm, t0,t1, t2, tres = Rms[i]\n",
    "    mf = np.load('alpha2/mfields_'+Rm+'.npz')\n",
    "    \n",
    "    b2 = np.mean(np.array(mf['bxm'])**2, axis=1) + np.mean(np.array(mf['bym'])**2, axis=1)\n",
    "    tarr = np.arange(len(b2))/tres\n",
    "    ax.plot(tarr,b2)\n",
    "    \n",
    "    #pick last value if t = -1\n",
    "    t2 = len(mf['bxm']) if t2 == -1 else t2 \n",
    "    \n",
    "    ax.axvline(t0/tres,color='r',linestyle='dashed')\n",
    "    ax.axvline(t1/tres,color='r',linestyle='dashed')\n",
    "    ax.axvline(t2/tres,color='r',linestyle='dashed')\n",
    "        \n",
    "    ax.set_yscale('log')\n",
    "    #ax.set_title(r'Rm '+Rm,fontsize=14)\n",
    "    ax.set_ylabel(Rm,fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic minimization with Nelder-Mead to get initial values\n",
    "\n",
    "This is basically finding the maximum a posteriori value, i.e., peak of the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "useLog = True # flag if we use log fit\n",
    "pinit = [0.02, 0.15] # reasonable initial guess\n",
    "if useLog:\n",
    "    pinit = np.log10(pinit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "Residuals as a function of $t$ or $z$ are computed as a sum of two penalty functions that penalize the fit from the top and bottom as\n",
    "\n",
    " $ \\mathcal{R} = | \\frac{\\epsilon_{R}}{\\epsilon_{T}} + \\frac{\\epsilon_{T}}{\\epsilon_{R}} -2| $,\n",
    " \n",
    " where $\\epsilon_{R}$ is the reconstructed EMF and $\\epsilon_{T}$ is the true EMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute residuals from true and reconstructed EMF\n",
    "def residuals(emf2T, emf2R, axis=0):\n",
    "    eR = np.sum(emf2R, axis=axis)\n",
    "    eT = np.sum(emf2T, axis=axis)\n",
    "    #sT = np.std(emf2T, axis=1)\n",
    "    resd = np.abs(eR/eT + eT/eR - 2.0)\n",
    "\n",
    "    return resd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "### Linear\n",
    "$\\epsilon_x = \\alpha B_x$\n",
    "\n",
    "$\\epsilon_y = \\alpha B_y$\n",
    "\n",
    "### Quadratic with quenching term\n",
    "$\\epsilon_x = \\alpha \\frac{ B_x$ }{1 + B^2/B_{Eq}^2} $\n",
    "\n",
    "$\\epsilon_y = \\alpha \\frac{ B_y$ }{1 + B^2/B_{Eq}^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isotropic residual function \n",
    "def model(x):\n",
    "    def emf2(x, y):\n",
    "        return x*x + y*y\n",
    "\n",
    "    if useLog:\n",
    "        alpha_00 = 10.0**x[0]\n",
    "        emf0     = 0.0\n",
    "        beq      = 10.0**x[1]\n",
    "    else:\n",
    "        alpha_00 = x[0]\n",
    "        emf0     = 0.0\n",
    "        beq      = x[1]\n",
    "\n",
    "    bxm  = df['Bx']\n",
    "    bym  = df['By']\n",
    "    b2t  = df['Bx']**2 + df['By']**2\n",
    "        \n",
    "    #first order alpha\n",
    "    #emfxR = alpha_00*bxm + emf0\n",
    "    #emfyR = alpha_00*bym + emf0\n",
    "\n",
    "    #second order alpha\n",
    "    alpha = alpha_00/(1.0 + b2t/beq**2.0)\n",
    "    emfxR = alpha*bxm + emf0\n",
    "    emfyR = alpha*bym + emf0\n",
    "    \n",
    "    return emfxR, emfyR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual fitting that transforms model into residual\n",
    "def fit(x):\n",
    "    def emf2(x, y):\n",
    "        return x*x + y*y\n",
    "\n",
    "    emfx = df['Ex'] \n",
    "    emfy = df['Ey']\n",
    "    emf2T = emf2(emfx, emfy)   #TRUE EMF mfield\n",
    "    \n",
    "    emfxR, emfyR = model(x)\n",
    "    emf2R = emf2(emfxR, emfyR) #reconstructed field\n",
    "    \n",
    "    # actual residuals are calculated here\n",
    "    resd = residuals(emf2T, emf2R, axis=0)\n",
    "    \n",
    "    return resd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "As a likelihood, we just sum over the residuals and take log as\n",
    "\n",
    "$ \\mathcal{L} = \\log \\sum_{t/z} |\\mathcal{R_{t/z}}| $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse residuals into likelihood\n",
    "def lhood(x):\n",
    "    return np.log(np.sum( np.abs(fit(x)) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nelder-Mead aka Amoeba fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the fit\n",
    "fig, axs = plt.subplots(ncols=len(Rms), figsize=(6.974,3), sharey=True)\n",
    "#plt.subplots_adjust(left=0.2, hspace=0.25)\n",
    "\n",
    "def nelder_mead(df):\n",
    "    res = minimize(lhood, \n",
    "                   pinit,\n",
    "                   method='Nelder-Mead',\n",
    "                   tol=1.0e-4\n",
    "                   )\n",
    "    print(res.x)\n",
    "    return res\n",
    "\n",
    "for i in range(len(Rms)):\n",
    "    fname,t0,t1,t2,tres = Rms[i]\n",
    "    \n",
    "    fname_full_path = 'alpha2/mfields_'+fname+'.npz'\n",
    "    print()\n",
    "    print(fname_full_path)\n",
    "    \n",
    "    #df = gen_df_tave(fname=fname_full_path, t1=t1, t2=t2,verbose=1)\n",
    "    df = gen_df_zave(fname=fname_full_path, z1=0, z2=-1, verbose=1)\n",
    "    res = nelder_mead(df)\n",
    "    \n",
    "    #plot amoeba results\n",
    "    ax = axs[i]\n",
    "    ax.minorticks_on()\n",
    "    ax.set_xlabel(r'Time (resistive)')\n",
    "    ax.set_yscale('log')            \n",
    "    ax.set_ylabel(r'$\\varepsilon^2$')\n",
    "\n",
    "    #True field for comparison\n",
    "    emf2  = df['Ex']**2 + df['Ey']**2\n",
    "    tarr = np.arange(len(emf2))/tres\n",
    "    ax.plot(tarr, emf2, 'r-', label=r'<\\varepsilon$^2$>')\n",
    "\n",
    "    #reconstruction\n",
    "    exF, eyF = model(res.x)\n",
    "    emf2F = exF*exF + eyF*eyF\n",
    "    ax.plot(tarr, emf2F, 'b-', label=r'fit $\\alpha_0$')\n",
    "\n",
    "    #legends\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    #ax.legend(handles, labels, fontsize=10, loc=4, frameon=False)\n",
    "    \n",
    "\n",
    "    \n",
    "plt.subplots_adjust(left=0.15, bottom=0.15, right=0.98, top=0.92)\n",
    "plt.savefig(\"mcmc_data.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n",
    "First, Amoeba is run (again) and the best-fit is used as a starting guess for the MCMC chain.\n",
    "\n",
    "This needs to be run only once, if you have already ran this and produced the chain file, you can just skip to the next section where results are visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse residuals into likelihood;\n",
    "#this is basically same as lhood() function but we just clean the results\n",
    "#by imposing sharp priors for unphysical results.\n",
    "\n",
    "def sanity_check(x):\n",
    "    if useLog:\n",
    "        for xi in x:\n",
    "            if xi < -4.0 or xi > 2.0:\n",
    "                return False\n",
    "    else:\n",
    "        for xi in x:\n",
    "            if xi < 0.0 or xi > 10.0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "linf = np.inf\n",
    "def lprob(x):\n",
    "    if not(sanity_check(x)):\n",
    "        return -linf\n",
    "\n",
    "    lp = lhood(x)\n",
    "    return -lp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee \n",
    "isotrop=True #extra switch for anisotropic fit (testing only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Rms)):\n",
    "    fname,t0,t1,t2,tres = Rms[i]\n",
    "\n",
    "    fname_full_path = 'alpha2/mfields_'+Rm+'.npz'\n",
    "    print()\n",
    "    print(fname_full_path)\n",
    "    \n",
    "    #df = gen_df_tave(fname=fname_full_path, t1=t1, t2=t2,verbose=1)\n",
    "    df = gen_df_zave(fname=fname_full_path, z1=0, z2=-1, verbose=1)\n",
    "    res = nelder_mead(df)\n",
    "    \n",
    "    #initialization\n",
    "    \n",
    "    if isotrop:\n",
    "        pinit = res.x #initial guess from non-linear fit\n",
    "    else:\n",
    "        pinit = np.zeros(5)\n",
    "        pinit[0] = res.x[0] #xx\n",
    "        pinit[1] = 0.0      #xy\n",
    "        pinit[2] = 0.0      #yx\n",
    "        pinit[3] = res.x[0] #yy\n",
    "        pinit[4] = res.x[1] #b\n",
    "    print(pinit)\n",
    "    \n",
    "    # number of walkers is roughly 3*number of parameters\n",
    "    nwalkers = 3*len(pinit)\n",
    "    ndim = len(pinit)\n",
    "    \n",
    "    #initialize small Gaussian ball around the initial point\n",
    "    p0 = [pinit + 1.0e-1*np.random.rand(ndim) for i in range(nwalkers)]\n",
    "    \n",
    "    #output\n",
    "    if isotrop:\n",
    "        filename = \"chain_0_Rm\" + str(fname)+\".h5\"\n",
    "    else:\n",
    "        filename = \"chain_0_ani_Rm\" + str(fname)+\".h5\"\n",
    "\n",
    "    backend = emcee.backends.HDFBackend(filename)\n",
    "    print(nwalkers)\n",
    "    print(ndim)\n",
    "    backend.reset(nwalkers, ndim) #no restart\n",
    "            \n",
    "    # initialize sampler\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "                nwalkers, \n",
    "                ndim, \n",
    "                lprob, \n",
    "                backend=backend, \n",
    "                )\n",
    "    \n",
    "    #and finally, run it until ~5000 steps\n",
    "    result = sampler.run_mcmc(p0, 5000, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize MCMC chains\n",
    "\n",
    "First, the chains need to be processed. We skip the burn-in (when walkers are just warming up) and thin the chain (to avoid autocorrelation of values).\n",
    "\n",
    "There are various ways we can check the sanity of MCMC chains. Here we employ the most usual tricks and produce:\n",
    "\n",
    "- trace (i.e., fit parameter values as a function of walker steps)\n",
    "- triangle (plot covariance of all parameters against each other)\n",
    "- draw samples from the chain and visualize the reconstructed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "burnin = 100\n",
    "thin = 1\n",
    "\n",
    "for i in range(len(Rms)):\n",
    "    fname,t0,t1,t2,tres = Rms[i]\n",
    "    \n",
    "    if isotrop:\n",
    "        filename = 'chain_0_Rm' + str(fname) + '.h5'\n",
    "    else:\n",
    "        filename = 'chain_0_ani_Rm' + str(fname) + '.h5'\n",
    "    print(filename)\n",
    "    reader = emcee.backends.HDFBackend(filename)\n",
    "\n",
    "    # estimate autocorrelation time (can be used for the thinning)\n",
    "    #tau = reader.get_autocorr_time()\n",
    "    #print(\"autocorr time: {}\".format(tau))\n",
    "\n",
    "    samples = reader.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "    log_prob_samples = reader.get_log_prob(discard=burnin, flat=True, thin=thin)\n",
    "    #blob_samples = reader.get_blobs(discard=burnin, flat=True, thin=thin)\n",
    "\n",
    "    print(\"burn-in: {0}\".format(burnin))\n",
    "    print(\"thin: {0}\".format(thin))\n",
    "    print(\"flat chain shape: {0}\".format(samples.shape))\n",
    "    print(\"flat log prob shape: {0}\".format(log_prob_samples.shape))\n",
    "    #print(\"flat blob shape: {0}\".format(blob_samples.shape))\n",
    "\n",
    "    all_samples = samples\n",
    "    print(np.shape(all_samples))\n",
    "    if isotrop:\n",
    "        labels = [r\"$\\alpha$\", r\"$B_{eq}$\"]\n",
    "    else:\n",
    "        labels = [\n",
    "          r\"$\\alpha_{xx}$\", \n",
    "          r\"$\\alpha_{xy}$\", \n",
    "          r\"$\\alpha_{yx}$\", \n",
    "          r\"$\\alpha_{yy}$\", \n",
    "          r\"$B_{eq}$\"]\n",
    "\n",
    "    ndim = len(labels)\n",
    "    print(labels)\n",
    "    ##################################################\n",
    "    # triangle/corner plot\n",
    "\n",
    "    if True:\n",
    "        print(\"triangle\")\n",
    "        fig = corner.corner(all_samples, \n",
    "            #quantiles=[0.16, 0.5, 0.84],\n",
    "            #show_titles=True, \n",
    "            #title_kwargs={\"fontsize\": 12})\n",
    "            labels=labels)\n",
    "    \n",
    "        plt.savefig(\"triangle_\"+ str(fname)+\".pdf\")\n",
    "\n",
    "    ##################################################\n",
    "    # trace plot\n",
    "    if True:\n",
    "        print(\"trace\")\n",
    "\n",
    "        fig, axes = plt.subplots(ndim+1, figsize=(10, 7), sharex=True)\n",
    "        samples = reader.get_chain()\n",
    "        log_prob_samples = reader.get_log_prob()\n",
    "\n",
    "        labels.append(\"log(f)\")\n",
    "\n",
    "        for i in range(ndim):\n",
    "            ax = axes[i]\n",
    "            ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "            ax.set_xlim(0, len(samples))\n",
    "            ax.set_ylabel(labels[i])\n",
    "            ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "        #log prob\n",
    "        i = ndim\n",
    "        ax = axes[i]\n",
    "        ax.plot(log_prob_samples[:, :], \"k\", alpha=0.3)\n",
    "        ax.set_xlim(0, len(log_prob_samples))\n",
    "        ax.set_ylabel(labels[i])\n",
    "        ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "        axes[-1].set_xlabel(\"step number\");\n",
    "        plt.savefig(\"trace_0_\"+ str(fname)+\".pdf\")\n",
    "        \n",
    "    ###################################################\n",
    "    # model vs data\n",
    "    if True:\n",
    "        print(\"model\")\n",
    "    \n",
    "        plt.rc('font', family='serif')\n",
    "        plt.rc('xtick', labelsize=7)\n",
    "        plt.rc('ytick', labelsize=7)\n",
    "        plt.rc('axes', labelsize=9)\n",
    "        \n",
    "        fig = plt.figure(figsize=(3.54, 3.5)) #single column fig\n",
    "        #fig = plt.figure(figsize=(7.48, 4.0))  #two column figure\n",
    "        gs = plt.GridSpec(2, 1, hspace=0.12)\n",
    "        \n",
    "        axs = []\n",
    "        axs.append( plt.subplot(gs[0,0]) )\n",
    "        axs.append( plt.subplot(gs[1,0]) )\n",
    "        \n",
    "        for ax in axs:\n",
    "            ax.minorticks_on()\n",
    "            ax.set_xlabel(r'Time $t$')\n",
    "            #ax.set_xlim((0.0, 1000.0))\n",
    "        axs[0].set_yscale('log')\n",
    "        axs[1].set_yscale('log')\n",
    "        \n",
    "        axs[0].set_ylabel('EMF$^2$')\n",
    "        axs[1].set_ylabel('$\\Delta$')\n",
    "    \n",
    "        # read arrays\n",
    "        fname_full_path = 'alpha2/'+fname+'/mfields.npz'\n",
    "        print()\n",
    "        print(fname_full_path)\n",
    "    \n",
    "        #df = gen_df_tave(fname=fname_full_path, t1=t1, t2=t2,verbose=1)\n",
    "        df = gen_df_zave(fname=fname_full_path, z1=0, z2=-1, verbose=1)\n",
    "\n",
    "        #True field for comparison\n",
    "        emf2  = df['Ex']**2 + df['Ey']**2\n",
    "        axs[0].plot(emf2, 'r-', label=r'<EMF$^2$>')\n",
    "\n",
    "        #samples drawn from posteriors\n",
    "        samples = reader.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "        niter, nparam = samples.shape\n",
    "        \n",
    "        print(\"plotting {} samples\".format(len(range(0,niter,20))))\n",
    "        for ix in range(0, niter, 20):\n",
    "            p0 = samples[ix,:ndim]\n",
    "\n",
    "            #reconstruction\n",
    "            exF, eyF = model(p0)\n",
    "            emf2F = exF*exF + eyF*eyF\n",
    "            axs[0].plot(emf2F, 'b-', alpha=0.2)\n",
    "\n",
    "            # residuals\n",
    "            resd = fit(p0)\n",
    "            axs[1].plot(resd, 'g-', alpha=0.2)\n",
    "\n",
    "        #legends\n",
    "        handles, labels = axs[0].get_legend_handles_labels()\n",
    "        axs[0].legend(handles, labels, fontsize=6, loc=4, frameon=False)\n",
    "    \n",
    "        #axs[0].set_ylim((1.0e-12, 1.0e-7))\n",
    "    \n",
    "        plt.subplots_adjust(left=0.2, bottom=0.12, right=0.98, top=0.95, wspace=0.0, hspace=0.0)\n",
    "        plt.savefig('data_Rm_0_' + str(fname) + '.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
